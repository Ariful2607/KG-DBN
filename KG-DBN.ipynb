{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBN architecture\n",
    "class DBN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(DBN, self).__init__()\n",
    "        self.rbm1 = RBM(input_dim, hidden_dim)\n",
    "        self.rbm2 = RBM(hidden_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.rbm1(x))\n",
    "        x = torch.sigmoid(self.rbm2(x))\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# RBM layer\n",
    "class RBM(nn.Module):\n",
    "    def __init__(self, visible_dim, hidden_dim):\n",
    "        super(RBM, self).__init__()\n",
    "        self.W = nn.Parameter(torch.randn(visible_dim, hidden_dim))\n",
    "        self.visible_bias = nn.Parameter(torch.randn(visible_dim))\n",
    "        self.hidden_bias = nn.Parameter(torch.randn(hidden_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        p_hidden_given_visible = torch.sigmoid(torch.matmul(x, self.W) + self.hidden_bias)\n",
    "        sampled_hidden = torch.bernoulli(p_hidden_given_visible)\n",
    "        p_visible_given_hidden = torch.sigmoid(torch.matmul(sampled_hidden, self.W.t()) + self.visible_bias)\n",
    "        return p_visible_given_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Neo4j and retrieve knowledge graph vectors\n",
    "class Neo4jDataLoader:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self._driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "    \n",
    "    def get_vectors(self):\n",
    "        with self._driver.session() as session:\n",
    "            # query = \"MATCH (node:Entity) RETURN node.vector AS vector\"\n",
    "            query = \"MATCH (n) RETURN n.Vector AS vector\"\n",
    "            result = session.run(query)\n",
    "            vectors = [record['vector'] for record in result]\n",
    "        return torch.tensor(vectors)\n",
    "neo4j_loader = Neo4jDataLoader(uri=\"neo4j://localhost:7687\", user=\"neo4j\", password=\"12345678\")\n",
    "data = neo4j_loader.get_vectors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"bolt://localhost:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"12345678\"\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "with driver.session() as session:\n",
    "    result = session.run(\"MATCH (n) RETURN n.label AS label\")\n",
    "    label = pd.DataFrame([record.values() for record in result], columns=result.keys())\n",
    "    \n",
    "# Extract the values from the 'label' column and convert to a one-dimensional list\n",
    "label_values = label['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0035,  0.0155,  0.0005,  ..., -0.0087, -0.0016, -0.0086],\n",
       "        [-0.0035,  0.0107, -0.0042,  ...,  0.0103,  0.0054,  0.0011],\n",
       "        [-0.0031, -0.0156,  0.0136,  ...,  0.0139, -0.0053,  0.0154],\n",
       "        ...,\n",
       "        [-0.0033, -0.0010,  0.0074,  ...,  0.0136,  0.0032,  0.0089],\n",
       "        [-0.0031,  0.0121, -0.0047,  ...,  0.0047, -0.0100, -0.0060],\n",
       "        [-0.0033,  0.0016, -0.0095,  ..., -0.0031,  0.0126, -0.0039]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         [0.4884479]\n",
      "1        [0.87393254]\n",
      "2        [0.21472734]\n",
      "3        [0.55303454]\n",
      "4       [-0.42872798]\n",
      "            ...      \n",
      "151      [0.20372128]\n",
      "152    [-0.071162105]\n",
      "153      [0.93546486]\n",
      "154      [-1.2053802]\n",
      "155      [-1.5844753]\n",
      "Name: embeddings, Length: 156, dtype: object\n",
      "tensor([[ 4.8845e-01],\n",
      "        [ 8.7393e-01],\n",
      "        [ 2.1473e-01],\n",
      "        [ 5.5303e-01],\n",
      "        [-4.2873e-01],\n",
      "        [ 1.9503e-01],\n",
      "        [-8.9595e-01],\n",
      "        [ 9.1032e-01],\n",
      "        [-4.1371e-01],\n",
      "        [-3.5485e-01],\n",
      "        [ 4.4958e-01],\n",
      "        [-8.1579e-01],\n",
      "        [-9.2834e-01],\n",
      "        [ 1.2550e+00],\n",
      "        [ 9.0775e-01],\n",
      "        [ 3.2137e-02],\n",
      "        [-1.4537e-01],\n",
      "        [ 5.0606e-01],\n",
      "        [ 1.1201e-01],\n",
      "        [ 6.7674e-01],\n",
      "        [ 1.3520e-01],\n",
      "        [ 1.3897e+00],\n",
      "        [ 9.5477e-01],\n",
      "        [-8.8707e-01],\n",
      "        [ 8.8868e-01],\n",
      "        [ 3.1072e-01],\n",
      "        [ 3.4036e-02],\n",
      "        [ 2.8477e-01],\n",
      "        [-1.8087e-01],\n",
      "        [-8.1328e-02],\n",
      "        [ 3.0743e-01],\n",
      "        [-8.5656e-02],\n",
      "        [ 8.2363e-01],\n",
      "        [ 2.0944e-01],\n",
      "        [ 6.0932e-01],\n",
      "        [ 6.0889e-01],\n",
      "        [-7.8861e-01],\n",
      "        [ 6.2738e-01],\n",
      "        [-1.1804e+00],\n",
      "        [ 2.5068e-02],\n",
      "        [-7.7788e-01],\n",
      "        [ 4.1747e-01],\n",
      "        [ 3.6977e-01],\n",
      "        [ 2.1778e-02],\n",
      "        [-8.7916e-01],\n",
      "        [ 9.7864e-01],\n",
      "        [ 1.4909e+00],\n",
      "        [-1.5580e-01],\n",
      "        [ 9.9408e-02],\n",
      "        [ 2.1198e-01],\n",
      "        [ 8.2454e-02],\n",
      "        [ 5.3644e-01],\n",
      "        [-7.2974e-01],\n",
      "        [-1.3989e+00],\n",
      "        [ 9.8828e-02],\n",
      "        [ 4.6721e-01],\n",
      "        [ 1.3563e+00],\n",
      "        [-2.4409e-01],\n",
      "        [-7.8512e-01],\n",
      "        [ 5.2511e-01],\n",
      "        [ 7.7317e-01],\n",
      "        [-9.4479e-01],\n",
      "        [-1.2471e+00],\n",
      "        [ 2.8607e-01],\n",
      "        [ 2.5613e+00],\n",
      "        [-5.3731e-01],\n",
      "        [ 8.3818e-01],\n",
      "        [ 1.0888e+00],\n",
      "        [ 7.5451e-01],\n",
      "        [ 3.1326e-01],\n",
      "        [ 3.4692e-01],\n",
      "        [ 6.6172e-01],\n",
      "        [-4.7468e-01],\n",
      "        [-8.7576e-01],\n",
      "        [ 1.7900e-01],\n",
      "        [ 1.7610e-01],\n",
      "        [-2.8395e-01],\n",
      "        [-1.5457e-01],\n",
      "        [ 1.4087e+00],\n",
      "        [-3.0510e-01],\n",
      "        [ 9.2331e-01],\n",
      "        [ 1.5656e+00],\n",
      "        [-6.1933e-02],\n",
      "        [ 1.0959e+00],\n",
      "        [-4.6380e-01],\n",
      "        [ 3.0812e-01],\n",
      "        [ 4.6724e-01],\n",
      "        [-9.3701e-01],\n",
      "        [-1.1373e+00],\n",
      "        [-3.6652e-01],\n",
      "        [ 4.6309e-01],\n",
      "        [-9.5725e-01],\n",
      "        [ 2.3676e-01],\n",
      "        [-7.8755e-02],\n",
      "        [ 6.5098e-01],\n",
      "        [ 1.2687e+00],\n",
      "        [-2.1939e-01],\n",
      "        [ 0.0000e+00],\n",
      "        [ 1.0095e+00],\n",
      "        [-1.3264e+00],\n",
      "        [ 2.9352e-01],\n",
      "        [ 7.4334e-01],\n",
      "        [-5.7665e-01],\n",
      "        [ 2.5840e+00],\n",
      "        [ 3.0109e-02],\n",
      "        [-1.5733e+00],\n",
      "        [-7.6998e-01],\n",
      "        [-2.1564e-01],\n",
      "        [ 4.5722e-03],\n",
      "        [ 1.4735e+00],\n",
      "        [ 1.7561e-03],\n",
      "        [ 1.4288e+00],\n",
      "        [-1.4944e-01],\n",
      "        [-2.1768e-01],\n",
      "        [-5.6000e-01],\n",
      "        [-1.3215e+00],\n",
      "        [-6.1735e-01],\n",
      "        [-1.0388e+00],\n",
      "        [-1.3767e+00],\n",
      "        [-8.3831e-02],\n",
      "        [-5.0082e-01],\n",
      "        [-8.6197e-01],\n",
      "        [ 6.2388e-01],\n",
      "        [ 6.0473e-01],\n",
      "        [-7.3821e-01],\n",
      "        [-5.0602e-01],\n",
      "        [ 1.3219e+00],\n",
      "        [ 4.2751e-01],\n",
      "        [ 3.6657e-01],\n",
      "        [-8.0080e-02],\n",
      "        [-5.6181e-02],\n",
      "        [-9.0327e-01],\n",
      "        [ 2.3484e-01],\n",
      "        [ 1.2244e+00],\n",
      "        [ 3.8827e-01],\n",
      "        [ 5.8855e-01],\n",
      "        [-3.6747e-01],\n",
      "        [ 9.5385e-01],\n",
      "        [-1.1833e+00],\n",
      "        [-9.0790e-02],\n",
      "        [ 2.4982e+00],\n",
      "        [-6.7290e-01],\n",
      "        [ 1.6707e+00],\n",
      "        [ 2.6795e-01],\n",
      "        [-1.9953e-01],\n",
      "        [ 6.7646e-01],\n",
      "        [-3.1343e-01],\n",
      "        [-2.9618e-02],\n",
      "        [-1.4710e+00],\n",
      "        [-4.7575e-01],\n",
      "        [ 1.8805e+00],\n",
      "        [ 2.0372e-01],\n",
      "        [-7.1162e-02],\n",
      "        [ 9.3546e-01],\n",
      "        [-1.2054e+00],\n",
      "        [-1.5845e+00]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Define a Word2Vec model (you need to define this as you did before)\n",
    "sentences = [str(text).split() for text in label_values]\n",
    "model = Word2Vec(sentences, vector_size=1, window=5, min_count=1, sg=0)\n",
    "\n",
    "# Function to get embeddings for a list of words\n",
    "def get_sentence_embedding(word_list):\n",
    "    word_vectors = [model.wv[word] for word in word_list if word in model.wv.key_to_index]\n",
    "    \n",
    "    if word_vectors:\n",
    "        sentence_embedding = sum(word_vectors)\n",
    "        return sentence_embedding\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'text_data': label_values}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split the text_data column into lists of words and apply the function to each row\n",
    "df['text_data'] = df['text_data'].apply(lambda x: x.split() if x is not None else [])\n",
    "df['embeddings'] = df['text_data'].apply(lambda x: get_sentence_embedding(x) if x else None)\n",
    "\n",
    "print(df['embeddings'])\n",
    "\n",
    "# # Filter out rows where embeddings are not available\n",
    "# df = df.dropna(subset=['embeddings'])\n",
    "\n",
    "# Replace rows where embeddings are not available with a default value (e.g., zeros)\n",
    "default_embedding = np.zeros(1)  # Replace with your desired default value\n",
    "df['embeddings'] = df['embeddings'].apply(lambda x: x if x is not None else default_embedding)\n",
    "\n",
    "# Convert embeddings to a PyTorch tensor\n",
    "embeddings_tensor = torch.tensor(df['embeddings'].to_list())\n",
    "\n",
    "print(embeddings_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([156, 1])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\arifu\\Research\\KG-DBN.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arifu/Research/KG-DBN.ipynb#W5sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch [\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/100], Loss: \u001b[39m\u001b[39m{\u001b[39;00mtotal_loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(dataloader)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arifu/Research/KG-DBN.ipynb#W5sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/arifu/Research/KG-DBN.ipynb#W5sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     train_dbn()\n",
      "\u001b[1;32mc:\\Users\\arifu\\Research\\KG-DBN.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arifu/Research/KG-DBN.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arifu/Research/KG-DBN.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m output \u001b[39m=\u001b[39m dbn(inputs)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/arifu/Research/KG-DBN.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, targets)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arifu/Research/KG-DBN.ipynb#W5sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arifu/Research/KG-DBN.ipynb#W5sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\arifu\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\arifu\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1164\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m-> 1164\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m   1165\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[0;32m   1166\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[1;32mc:\\Users\\arifu\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:3014\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3012\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3013\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3014\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "# Main training loop\n",
    "def train_dbn():\n",
    "    # Initialize DBN and other hyperparameters\n",
    "    input_dim = 32  # Adjust based on the dimensionality of your knowledge graph vectors\n",
    "    hidden_dim = 32\n",
    "    output_dim = 2  # Adjust based on your task (e.g., classification)\n",
    "\n",
    "    dbn = DBN(input_dim, hidden_dim, output_dim)\n",
    "    optimizer = optim.Adam(dbn.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Connect to Neo4j and retrieve data\n",
    "    neo4j_loader = Neo4jDataLoader(uri=\"neo4j://localhost:7687\", user=\"neo4j\", password=\"12345678\")\n",
    "    data = neo4j_loader.get_vectors()\n",
    "\n",
    "    # Load labels for your data\n",
    "    labels = embeddings_tensor\n",
    "\n",
    "    # Create a DataLoader to handle batching (if needed)\n",
    "    batch_size = 32  # Adjust based on your dataset size\n",
    "    dataset = TensorDataset(data, labels)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(100):  # Adjust the number of epochs\n",
    "        total_loss = 0.0\n",
    "        for inputs, targets in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            output = dbn(inputs)\n",
    "            loss = criterion(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/100], Loss: {total_loss / len(dataloader)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_dbn()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
